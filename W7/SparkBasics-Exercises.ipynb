{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal of these exercises is to get familiar with pyspark APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheat Sheet\n",
    "**Transformation operations:**\n",
    "- map: Takes a function as input and applies it to each element in the source RDD to create a new RDD\n",
    "- flatMap: Takes an input function, which returns a sequence for each input element passed to it returns a new RDD formed by flattening this collection of sequence\n",
    "- filter: Takes a Boolean function as input and applies it to each element in the source RDD to create a new RDD by selecting only those elements for which the input Boolean function returned true\n",
    "- distinct: The distinct method of an RDD returns a new RDD containing the distinct elements in the source RDD.\n",
    "- zip:takes an RDD as input and returns an RDD of pairs, where the first element in a pair is from the source RDD and second element is from the input RDD. Both the source RDD and the input RDD must have the same length.\n",
    "- groupBy: Groups the elements of an RDD according to a user specified criteria. In each returned pair, the first item is a key and the second item is a collection of the elements mapped to that key by the input function to the groupBy method.\n",
    "- sortBy: returns an RDD with sorted elements from the source RDD. It takes two input parameters. The first input is a function that generates a key for each element in the source RDD. The second argument allows you to specify ascending or descending order for sort.\n",
    "- sample: Returns a sampled subset of the source RDD. It takes three input parameters. The first parameter specifies the replacement strategy. The second parameter specifies the ratio of the sample size to source RDD size.\n",
    "- union: Return the union of this RDD and another one.\n",
    "- intersection: Return the intersection of this RDD and another one. The output will not contain any duplicate elements, even if the input RDDs did.\n",
    "\n",
    "**Action operations:**\n",
    "- collect: Returns the elements in the source RDD as an array. **It can crash the driver program if called on a very large RDD.**\n",
    "- count: The count method returns a count of the elements in the source RDD.\n",
    "- countByValue: The countByValue method returns a count of each unique element in the source RDD\n",
    "- first: The first element in the source RDD.\n",
    "- max: Returns the largest element in an RDD. Similar idea for min\n",
    "- stdev: Compute the standard deviation of this RDDâ€™s elements.\n",
    "- take: takes an integer N as input and returns an array containing the first N element in the source RDD.\n",
    "- takeOrdered: takes an integer N as input and returns an array containing the N smallest elements in the source RDD.\n",
    "- top: takes an integer N as input and returns an array containing the N largest elements in the source RDD.\n",
    "- reduce: aggregates the elements of the source RDD using an associative and commutative binary operator provided to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the SparkContext\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext \n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 91, 77, 24, 33]\n"
     ]
    }
   ],
   "source": [
    "RDD_text = sc.textFile('Numbers.csv') # reads as text\n",
    "RDD = RDD_text.map(lambda x: int(x))\n",
    "print(RDD.take(5))\n",
    "# How many numbers are there\n",
    "\n",
    "# Max value\n",
    "\n",
    "# Min value\n",
    "\n",
    "# mean\n",
    "\n",
    "# Standard deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of even numbers\n",
    "\n",
    "# count of numbers greater than 80\n",
    "\n",
    "# sum of odd numbers\n",
    "\n",
    "# number of unique elements in the RDD\n",
    "\n",
    "# Summation of (x^2 + 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Working with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_words = sc.textFile('sonnetWords.txt')\n",
    "RDD_words = RDD_words.filter(lambda x: x!='')\n",
    "# How many words are there\n",
    "\n",
    "# How many unique words\n",
    "\n",
    "# How many words having at least 4 characters\n",
    "\n",
    "# Average number of characters per word\n",
    "\n",
    "# Number of unique words case-insensitive\n",
    "\n",
    "# Convert the words to UPPERCASE and show few samples\n",
    "\n",
    "# print the longest word (having highest number of characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHAPTER 1. Loomings.', 'Call me Ishmael. Some years ago--never mind how long precisely--having', 'little or no money in my purse, and nothing particular to interest me on']\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RDD_texts = sc.textFile('Moby-Dick.txt')\n",
    "RDD_texts = RDD_texts.filter(lambda line: line.strip())\n",
    "print(RDD_texts.take(3))\n",
    "# How many sentences are there\n",
    "\n",
    "# Show a sample sentence containing word 'delights'\n",
    "\n",
    "# Average number of words per sentence\n",
    "\n",
    "# replace all 'crazy' with 'genius' and show 3 examples\n",
    "\n",
    "# shortest sentence (in terms of number of words) in the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
